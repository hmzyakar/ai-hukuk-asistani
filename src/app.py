# This is the main file for our Streamlit user interface.

import streamlit as st
# Imports are now correct for a script running inside the 'src' directory
from scraper import get_todays_gazette_url, fetch_regulation_links, fetch_text_from_url
from analyzer import setup_ai_model, summarize_and_categorize_text

st.set_page_config(page_title="AI Hukuk AsistanÄ±", layout="wide")
st.title("âš–ï¸ AI Hukuk AsistanÄ±")
st.markdown("GÃ¼nlÃ¼k ResmÃ® Gazete gÃ¼ndemini sizin iÃ§in analiz eder ve Ã¶zetler.")

# Setup the AI model once
model = setup_ai_model()

st.divider()

if st.button("BugÃ¼nÃ¼n GÃ¼ndemini Getir"):
    if not model:
        st.error("AI model could not be initialized. Please check your API key in the .env file.")
    else:
        # Step 1: Get today's gazette URL
        with st.spinner("BugÃ¼nkÃ¼ ResmÃ® Gazete URL'i alÄ±nÄ±yor..."):
            gazette_url = get_todays_gazette_url()
            if not gazette_url:
                st.error("BugÃ¼nkÃ¼ ResmÃ® Gazete URL'i oluÅŸturulamadÄ±.")
                st.stop()

        st.info(f"Scraping this URL for links: {gazette_url}")
        
        # Step 2: Fetch regulation links from the gazette page
        with st.spinner("DÃ¼zenleme linkler aranÄ±yor..."):
            regulation_links = fetch_regulation_links(gazette_url)
            
            if not regulation_links:
                st.warning("BugÃ¼n ResmÃ® Gazete'de analiz edilecek yeni bir dÃ¼zenleme bulunamadÄ±.")
                st.stop()
            
            st.success(f"Toplam {len(regulation_links)} dÃ¼zenleme bulundu.")
        
        # Step 3: Process each regulation
        for i, link_url in enumerate(regulation_links, 1):
            with st.spinner(f"DÃ¼zenleme {i}/{len(regulation_links)} analiz ediliyor..."):
                # Fetch the text content from the regulation URL
                regulation_text = fetch_text_from_url(link_url)
                
                if not regulation_text:
                    st.warning(f"DÃ¼zenleme {i}: Metin iÃ§eriÄŸi alÄ±namadÄ±.")
                    continue
                
                # Analyze the text using the AI model
                category, summary = summarize_and_categorize_text(model, regulation_text)
                
                # Display the results
                st.subheader(f"ğŸ“‹ DÃ¼zenleme {i}: {category}")
                st.markdown(f"**Ã–zet:** {summary}")
                
                # Show the source link
                st.markdown(f"**Kaynak:** [DÃ¼zenleme metnini gÃ¶rÃ¼ntÃ¼le]({link_url})")
                st.divider()
        
        st.success("ğŸ‰ TÃ¼m dÃ¼zenlemeler baÅŸarÄ±yla analiz edildi!")